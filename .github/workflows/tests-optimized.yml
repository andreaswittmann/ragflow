name: tests-optimized

on:
  workflow_dispatch:

# https://docs.github.com/en/actions/using-jobs/using-concurrency
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  ragflow_tests:
    name: ragflow_tests
    # https://docs.github.com/en/actions/using-jobs/using-conditions-to-control-job-execution
    # https://github.com/orgs/community/discussions/26261
    runs-on: [ "self-hosted", "ragflow-test" ]
    env:
      ZHIPU_AI_API_KEY: ${{ secrets.ZHIPU_AI_API_KEY }}
    steps:
      # https://github.com/hmarr/debug-action
      #- uses: hmarr/debug-action@v2

      - name: Ensure workspace ownership
        run: |
          echo "Workflow triggered manually"
          echo "chown -R $USER $GITHUB_WORKSPACE" && sudo chown -R $USER $GITHUB_WORKSPACE

      # https://github.com/actions/checkout/issues/1781
      - name: Check out code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          fetch-tags: true

      - name: Debug ZHIPU_AI_API_KEY
        run: |
          if [ -z "$ZHIPU_AI_API_KEY" ]; then
            echo "ZHIPU_AI_API_KEY is not set or empty"
            exit 1
          else
            echo "ZHIPU_AI_API_KEY is set (length: ${#ZHIPU_AI_API_KEY})"
            if [[ "$ZHIPU_AI_API_KEY" == *","* ]]; then
              echo "Key contains comma, likely in correct format"
            else
              echo "Key does not contain comma"
            fi
          fi
          echo "ZHIPU_AI_API_KEY ${ZHIPU_AI_API_KEY}"  

      # https://github.com/astral-sh/ruff-action
      - name: Static check with Ruff
        uses: astral-sh/ruff-action@v3
        with:
          version: ">=0.11.x"
          args: "check"


      - name: Build ragflow:nightly (Simplified with Built-in Cache)
        run: |
          RUNNER_WORKSPACE_PREFIX=${RUNNER_WORKSPACE_PREFIX:-$HOME}
          RAGFLOW_IMAGE=infiniflow/ragflow:${GITHUB_RUN_ID}
          echo "RAGFLOW_IMAGE=${RAGFLOW_IMAGE}" >> $GITHUB_ENV
          
          # Enable Docker BuildKit for automatic layer caching
          export DOCKER_BUILDKIT=1
          
          # Pull base image
          echo "Pulling base image ubuntu:22.04..."
          sudo docker pull ubuntu:22.04
          
          # Build with Docker BuildKit (uses built-in layer caching)
          echo "Building Docker image with BuildKit layer caching..."
          sudo docker build \
            --build-arg NEED_MIRROR=1 \
            -f Dockerfile -t ${RAGFLOW_IMAGE} .
          
          # Standard test level configuration
          export HTTP_API_TEST_LEVEL=p2
          echo "HTTP_API_TEST_LEVEL=${HTTP_API_TEST_LEVEL}" >> $GITHUB_ENV
          echo "RAGFLOW_CONTAINER=${GITHUB_RUN_ID}-ragflow-cpu-1" >> $GITHUB_ENV
          
          echo "Build completed successfully with Docker layer caching enabled"

      - name: Start ragflow:nightly
        run: |
          # Determine runner number (default to 1 if not found)
          RUNNER_NUM=$(sudo docker inspect $(hostname) --format '{{index .Config.Labels "com.docker.compose.container-number"}}' 2>/dev/null || true)
          RUNNER_NUM=${RUNNER_NUM:-1}

          # Compute port numbers using bash arithmetic
          ES_PORT=$((1200 + RUNNER_NUM * 10))
          OS_PORT=$((1201 + RUNNER_NUM * 10))
          INFINITY_THRIFT_PORT=$((23817 + RUNNER_NUM * 10))
          INFINITY_HTTP_PORT=$((23820 + RUNNER_NUM * 10))
          INFINITY_PSQL_PORT=$((5432 + RUNNER_NUM * 10))
          MYSQL_PORT=$((5455 + RUNNER_NUM * 10))
          MINIO_PORT=$((9000 + RUNNER_NUM * 10))
          MINIO_CONSOLE_PORT=$((9001 + RUNNER_NUM * 10))
          REDIS_PORT=$((6379 + RUNNER_NUM * 10))
          TEI_PORT=$((6380 + RUNNER_NUM * 10))
          KIBANA_PORT=$((6601 + RUNNER_NUM * 10))
          SVR_HTTP_PORT=$((9380 + RUNNER_NUM * 10))
          ADMIN_SVR_HTTP_PORT=$((9381 + RUNNER_NUM * 10))
          SVR_MCP_PORT=$((9382 + RUNNER_NUM * 10))
          SANDBOX_EXECUTOR_MANAGER_PORT=$((9385 + RUNNER_NUM * 10))
          SVR_WEB_HTTP_PORT=$((80 + RUNNER_NUM * 10))
          SVR_WEB_HTTPS_PORT=$((443 + RUNNER_NUM * 10))

          # Persist computed ports into docker/.env so docker-compose uses the correct host bindings
          echo "" >> docker/.env
          echo -e "ES_PORT=${ES_PORT}" >> docker/.env
          echo -e "OS_PORT=${OS_PORT}" >> docker/.env
          echo -e "INFINITY_THRIFT_PORT=${INFINITY_THRIFT_PORT}" >> docker/.env
          echo -e "INFINITY_HTTP_PORT=${INFINITY_HTTP_PORT}" >> docker/.env
          echo -e "INFINITY_PSQL_PORT=${INFINITY_PSQL_PORT}" >> docker/.env
          echo -e "MYSQL_PORT=${MYSQL_PORT}" >> docker/.env
          echo -e "MINIO_PORT=${MINIO_PORT}" >> docker/.env
          echo -e "MINIO_CONSOLE_PORT=${MINIO_CONSOLE_PORT}" >> docker/.env
          echo -e "REDIS_PORT=${REDIS_PORT}" >> docker/.env
          echo -e "TEI_PORT=${TEI_PORT}" >> docker/.env
          echo -e "KIBANA_PORT=${KIBANA_PORT}" >> docker/.env
          echo -e "SVR_HTTP_PORT=${SVR_HTTP_PORT}" >> docker/.env
          echo -e "ADMIN_SVR_HTTP_PORT=${ADMIN_SVR_HTTP_PORT}" >> docker/.env
          echo -e "SVR_MCP_PORT=${SVR_MCP_PORT}" >> docker/.env
          echo -e "SANDBOX_EXECUTOR_MANAGER_PORT=${SANDBOX_EXECUTOR_MANAGER_PORT}" >> docker/.env
          echo -e "SVR_WEB_HTTP_PORT=${SVR_WEB_HTTP_PORT}" >> docker/.env
          echo -e "SVR_WEB_HTTPS_PORT=${SVR_WEB_HTTPS_PORT}" >> docker/.env

          echo -e "COMPOSE_PROFILES=\${COMPOSE_PROFILES},tei-cpu" >> docker/.env
          echo -e "TEI_MODEL=BAAI/bge-small-en-v1.5" >> docker/.env
          echo -e "RAGFLOW_IMAGE=${RAGFLOW_IMAGE}" >> docker/.env
          
          # Dynamically detect host IP to resolve host.docker.internal DNS issue
          HOST_IP=$(ip route get 1.1.1.1 | awk '{print $7; exit}')
          echo "Detected host IP: ${HOST_IP}"
          echo "HOST_ADDRESS=http://${HOST_IP}:${SVR_HTTP_PORT}" >> $GITHUB_ENV
          echo "HOST_IP=${HOST_IP}" >> $GITHUB_ENV

          sudo docker compose -f docker/docker-compose.yml -p ${GITHUB_RUN_ID} up -d
          uv sync --python 3.10 --only-group test --no-default-groups --frozen && uv pip install sdk/python

      - name: Run sdk tests against Elasticsearch
        run: |
          export http_proxy=""; export https_proxy=""; export no_proxy=""; export HTTP_PROXY=""; export HTTPS_PROXY=""; export NO_PROXY=""
          until sudo docker exec ${RAGFLOW_CONTAINER} curl -s --connect-timeout 5 ${HOST_ADDRESS} > /dev/null; do
            echo "Waiting for service to be available..."
            sleep 5
          done
          source .venv/bin/activate && pytest -s --tb=short --level=${HTTP_API_TEST_LEVEL} test/testcases/test_sdk_api

      - name: Run frontend api tests against Elasticsearch
        run: |
          export http_proxy=""; export https_proxy=""; export no_proxy=""; export HTTP_PROXY=""; export HTTPS_PROXY=""; export NO_PROXY=""
          until sudo docker exec ${RAGFLOW_CONTAINER} curl -s --connect-timeout 5 ${HOST_ADDRESS} > /dev/null; do
            echo "Waiting for service to be available..."
            sleep 5
          done
          source .venv/bin/activate && pytest -s --tb=short sdk/python/test/test_frontend_api/get_email.py sdk/python/test/test_frontend_api/test_dataset.py
          
      - name: Run http api tests against Elasticsearch
        run: |
          export http_proxy=""; export https_proxy=""; export no_proxy=""; export HTTP_PROXY=""; export HTTPS_PROXY=""; export NO_PROXY=""
          until sudo docker exec ${RAGFLOW_CONTAINER} curl -s --connect-timeout 5 ${HOST_ADDRESS} > /dev/null; do
            echo "Waiting for service to be available..."
            sleep 5
          done
          source .venv/bin/activate && pytest -s --tb=short --level=${HTTP_API_TEST_LEVEL} test/testcases/test_http_api

      - name: Stop ragflow:nightly
        if: always()  # always run this step even if previous steps failed
        run: |
          sudo docker compose -f docker/docker-compose.yml -p ${GITHUB_RUN_ID} down -v

      - name: Start ragflow:nightly
        if: true
        run: |
          # Ensure completely clean environment before second run
          echo "Cleaning up any previous containers and volumes..."
          sudo docker compose -f docker/docker-compose.yml -p ${GITHUB_RUN_ID} down -v || true
          sudo docker volume prune -f
          sudo docker network prune -f

          # Reset configuration and start fresh
          sed -i '1i DOC_ENGINE=infinity' docker/.env
          sudo docker compose -f docker/docker-compose.yml -p ${GITHUB_RUN_ID} up -d

      - name: Run sdk tests against Infinity
        if: true
        run: |
          export http_proxy=""; export https_proxy=""; export no_proxy=""; export HTTP_PROXY=""; export HTTPS_PROXY=""; export NO_PROXY=""
          until sudo docker exec ${RAGFLOW_CONTAINER} curl -s --connect-timeout 5 ${HOST_ADDRESS} > /dev/null; do
            echo "Waiting for service to be available..."
            sleep 5
          done
          source .venv/bin/activate && DOC_ENGINE=infinity pytest -s --tb=short --level=${HTTP_API_TEST_LEVEL} test/testcases/test_sdk_api

      - name: Run frontend api tests against Infinity
        if: true
        run: |
          export http_proxy=""; export https_proxy=""; export no_proxy=""; export HTTP_PROXY=""; export HTTPS_PROXY=""; export NO_PROXY=""
          until sudo docker exec ${RAGFLOW_CONTAINER} curl -s --connect-timeout 5 ${HOST_ADDRESS} > /dev/null; do
            echo "Waiting for service to be available..."
            sleep 5
          done
          source .venv/bin/activate && DOC_ENGINE=infinity pytest -s --tb=short sdk/python/test/test_frontend_api/get_email.py sdk/python/test/test_frontend_api/test_dataset.py

      - name: Run http api tests against Infinity
        if: true
        run: |
          export http_proxy=""; export https_proxy=""; export no_proxy=""; export HTTP_PROXY=""; export HTTPS_PROXY=""; export NO_PROXY=""
          until sudo docker exec ${RAGFLOW_CONTAINER} curl -s --connect-timeout 5 ${HOST_ADDRESS} > /dev/null; do
            echo "Waiting for service to be available..."
            sleep 5
          done
          source .venv/bin/activate && DOC_ENGINE=infinity pytest -s --tb=short --level=${HTTP_API_TEST_LEVEL} test/testcases/test_http_api

      - name: Stop ragflow:nightly
        if: true
        run: |
          sudo docker compose -f docker/docker-compose.yml -p ${GITHUB_RUN_ID} down -v
          # Clean up ALL volumes and networks to prevent residue from affecting next run
          sudo docker volume prune -f
          sudo docker network prune -f
          sudo docker rmi -f ${RAGFLOW_IMAGE}

      - name: Docker cache cleanup (optional)
        if: false
        run: |
          echo "Docker system cleanup requested..."
          echo "Current Docker disk usage:"
          docker system df
          echo ""
          echo "Cleaning up Docker build cache and unused resources..."
          sudo docker builder prune --all --force
          echo "Docker system cleanup completed"
          echo "Docker disk usage after cleanup:"
          docker system df